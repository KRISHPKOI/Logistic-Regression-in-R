---
title: "Logistic Regression in R"
author: "Krishna P Koirala"
date: "6/1/2018"
output:
   md_document:
     variant: markdown_github
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```



```{r}
df.train <- read.csv("titanic_train.csv")
```

```{r}
head(df.train)
```

```{r}
str(df.train)
```

# EDA


```{r}
summary(df.train)
```

# Age column has 177 nas

```{r}
library(ggplot2)
ggplot(aes(Survived), data = df.train) + geom_bar()
```

# Bar Plots

```{r}
ggplot(aes(Pclass), data = df.train) + geom_bar(aes(fill = factor(Survived)))
ggplot(aes(Pclass), data = df.train) + geom_bar(aes(fill = factor(Pclass))) + facet_wrap(~Sex)
ggplot(aes(Pclass), data = df.train) + geom_bar(aes(fill = factor(Sex))) + facet_wrap(~Survived)
```


# Histograms

```{r}
ggplot(aes(Age), data = df.train) + geom_histogram( fill = 'blue') + facet_wrap(~Sex ) + theme_classic()
```

```{r}
ggplot(aes(SibSp), data = df.train) + geom_bar(aes(fill = factor(SibSp))) + facet_wrap(~Survived)
```


```{r}
ggplot(aes(Fare), data = df.train) + geom_histogram(fill = 'green', color = 'black', alpha = 0.5)
```

# Dealing with missing values
fill the average age by class on those places

```{r}
ggplot(aes(Pclass, Age), data = df.train) + geom_boxplot(aes(group = Pclass, fill = factor(Pclass), alpha = 0.4)) + scale_y_continuous(breaks = seq(0, 80, 2)) + theme_dark()

by(subset(df.train, (!is.na(Age) == Age))$Age, subset(df.train, (!is.na(Age) == Age))$Pclass, mean)
```

# Imputation of Age based on Pclass

```{r}
impute_age <- function(age, class){
    out <- age
    for (i in 1:length(age)){
        if (is.na(age[i])){
            if (class[1]==1){
                out[i] <- 38
            }else if (class[1]==2){
                out[i] <- 30
            }else{
                out[i] <- 25
            }
        }else{
            out[i] <- age[i]
        }
    }
    return(out)
}
fixed.ages <- impute_age(df.train$Age, df.train$Pclass)
```

```{r}
# Assigning the fixed value to the Age column
df.train$Age <- fixed.ages
```

```{r}
# Checking the summary of df.train
# Looks cool, its fixed now
summary(df.train)
```

# Model building

```{r}
colnames(df.train)
# Selectin only needed columns
library(dplyr)
df.train <- subset(df.train, select = -c(PassengerId, Name, Ticket, Cabin))
#df.train_new <- select(df.train, -c(PassengerId, Name, Ticket, Cabin))
```

```{r}
colnames(df.train)
```

```{r}
str(df.train)
```

```{r}
# changing to factors
#df.train$Survived <- factor(df.train$Survived)
#df.train$Pclass <- factor(df.train$Pclass)
#df.train$Parch <- factor(df.train$Parch)
#df.train$SibSp <- factor(df.train$SibSp)
```

```{r}
str(df.train)
```

```{r}
# Creatinng model
log.model <- glm(Survived ~. , family = binomial(link = 'logit'), data = df.train)
```

```{r}
summary(log.model)
```

# Prediction 

```{r}
df.test <- read.csv('titanic_test.csv')
```

```{r}
str(df.test)
```

```{r}
# Remove some columns
library(dplyr)
df.test <- subset(df.test, select = -c(PassengerId, Name, Ticket, Cabin))
```

```{r}
str(df.test)
```


```{r}
summary(df.test)
```

# Dealing with Nas of test data


```{r}
y = subset(df.test, (!is.na(Age) == Age) & (!is.na(Fare) == Fare))
summary(y)
```

```{r}
ggplot(aes(factor(Pclass), Age), data = df.test) + geom_boxplot() + scale_y_continuous(breaks = seq(0, 80, 2)) + theme_dark()
by(subset(df.test, (!is.na(Age) == Age))$Age, subset(df.test, (!is.na(Age) == Age))$Pclass, mean)
```

Now I want to replace nas of Age by 40 where Pclass =1, 
nas of Age by 28 where Pclass =2, nas of Age by 24 where Pclass =3,



```{r}
# Imputation of Age based of Pclass

impute_age1 <- function(age, class){
    out <- age
    for (i in 1:length(age)){
        if (is.na(age[i])){
            if (class[1]==1){
                out[i] <- 40
            }else if (class[1]==2){
                out[i] <- 28
            }else{
                out[i] <- 24
            }
        }else{
            out[i] <- age[i]
        }
    }
    return(out)
}
fixed.ages <- impute_age1(df.test$Age, df.test$Pclass)
```


```{r}
df.test$Age <- fixed.ages
```


```{r}
summary(df.test)
str(df.test)
```

Fare contains 1 NA, I want to remove it.

```{r}
# Removing rows containing 1 NA in Fare column
df.test <- na.omit(df.test)
```

```{r}
# Checking if the Fare column still contains na
filter(df.test,  is.na(Fare))
```

```{r}
# changing to factors
#df.test$Pclass <- factor(df.test$Pclass)
#df.test$Parch <- factor(df.test$Parch)
#df.test$SibSp <- factor(df.test$SibSp)
```


```{r}
str(df.test)
```


```{r}
df.test$Pred_Prob <- predict(log.model, df.test, type =  'response')
head(df.test)
```


```{r}
# create a predicted class variable to represent the predicted catagory:
#Predicted Survived = 1 if predicted probability >= 0.50
#Predicted Survived = 0 if predicted probability < 0.50
df.test$Survived_Predicted <- ifelse(df.test$Pred_Prob >= 0.5, 1, 0)
```


Create a confuision matrix to summarize original Survived and the predicted Survived for the test dataset(df.test)

```{r}
head(df.test)
```


Finally I predicted the Survived people using the test data set. Survived_Predicted is the column of predictioin from the model.

# Spliting train data and building model to check accuracy.

```{r}
library(caret)
library(lattice)
set.seed(101)
trainIndex <- createDataPartition(df.train$Survived, p = .7, list = FALSE) 
head(trainIndex)
final.train <- df.train[ trainIndex,]
final.test  <- df.train[-trainIndex,]
```

```{r}
final.log.model <- glm(Survived ~., family = binomial(link = 'logit'), data = final.train)
```

```{r}
summary(final.log.model)
```

```{r}
fitted.probabilities <- predict(final.log.model, final.test, type = 'response')
```

```{r}
fitted.results <- ifelse(fitted.probabilities > 0.5, 1, 0)
```

# Misclassification error
```{r}
misClassError <- mean(fitted.results !=final.test$Survived)
```

# Accuracy of the final.log.model(This is the Confusion matrix)

```{r}
accuracy <- 1-misClassError
accuracy
```

# Confusion Matrix

```{r}
table(final.test$Survived, fitted.probabilities > 0.5)
```


